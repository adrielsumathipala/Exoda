{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets country names in CSV to match world.json names (GeoJSON):\n",
    "def clean_names(tbl):\n",
    "    tbl = tbl.replace('Bolivia (Plurinational State of)', \"Bolivia\")\n",
    "    tbl = tbl.replace(\"Iran (Islamic Rep. of)\", \"Iran\")\n",
    "    tbl = tbl.replace(\"Rep. of Korea\", \"South Korea\")\n",
    "    tbl = tbl.replace(\"Rep. of Moldova\", \"Moldova\")\n",
    "    tbl = tbl.replace(\"Russian Federation\", \"Russia\")\n",
    "    tbl = tbl.replace(\"Dem. Rep. of the Congo\", \"Democratic Republic of the Congo\")\n",
    "    tbl = tbl.replace(\"United Rep. of Tanzania\", \"Tanzania\")\n",
    "    tbl = tbl.replace(\"Syrian Arab Rep.\", \"Syria\")\n",
    "    tbl = tbl.replace(\"Serbia and Kosovo (S/RES/1244 (1999))\", \"Serbia\")\n",
    "    tbl = tbl.replace(\"Lao People's Dem. Rep.\", \"Lao PDR\")\n",
    "    tbl = tbl.replace(\"Dem. People's Rep. of Korea\", \"Dem. Rep. Korea\")\n",
    "    tbl = tbl.replace(\"Viet Nam\", \"Vietnam\")\n",
    "    tbl = tbl.replace(\"The former Yugoslav Republic of Macedonia\", \"Macedonia\")\n",
    "    tbl = tbl.replace('Venezuela (Bolivarian Republic of)', \"Venezuela\")\n",
    "    tbl = tbl.replace('China, Hong Kong SAR', \"Hong Kong\")\n",
    "    tbl = tbl.replace('Brunei Darussalam', \"Brunei\")\n",
    "    tbl = tbl.replace('China, Macao SAR', \"Macao\")\n",
    "    tbl = tbl.replace('Micronesia (Federated States of)', \"Micronesia\")\n",
    "    tbl = tbl.replace('United States of America', \"United States\")\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country to Country Refugee Statistics:\n",
    "- Binding JSON Data\n",
    "- Using `clean_unhcr_refugee.csv`\n",
    "- This dataset includes \"Persons of Interest\" according to the UNHCR:\n",
    "   - Refugees (incl. refugee-like situations)\n",
    "   - Asylum-seekers (pending cases)\n",
    "   - Returned refugees\n",
    "   - Internally displaced persons (IDPs)\n",
    "   - Returned IDPs\n",
    "   - Stateless persons\n",
    "   - Others of concern\n",
    "- Source: http://popstats.unhcr.org/en/persons_of_concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'clean_unhcr_refugee.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-07cb9ccbbcda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrefugee_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clean_unhcr_refugee.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0masylum_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefugee_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"asylum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefugee_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"asylum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"asylum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'clean_unhcr_refugee.csv' does not exist"
     ]
    }
   ],
   "source": [
    "with open(\"world.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "refugee_table = pd.read_csv(\"clean_unhcr_refugee.csv\", delimiter=',', encoding=\"latin-1\")\n",
    "asylum_set = set(refugee_table[\"asylum\"].unique())\n",
    "total = refugee_table.groupby([\"asylum\", \"year\"]).sum().reset_index().set_index(\"asylum\")\n",
    "total = clean_names(total)\n",
    "\n",
    "tmp = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"origin\",\"refugees\"], ascending =False)\n",
    "tmp = tmp[tmp[\"asylum\"]!=tmp[\"origin\"]]\n",
    "# Top 5 places refugees are leaving to:\n",
    "asylum = tmp.groupby(\"origin\").head(5)\n",
    "\n",
    "refugees = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"asylum\",\"refugees\"], ascending =False)\n",
    "refugees = refugees[refugees[\"asylum\"]!=refugees[\"origin\"]]\n",
    "# Top 5 places refugees are coming from:\n",
    "refugees = refugees.groupby(\"asylum\").head(5)\n",
    "\n",
    "for country in data[\"features\"]:\n",
    "    country_name = country[\"properties\"][\"name\"]\n",
    "    if(country_name in asylum_set):\n",
    "        years = total.loc[country_name][\"year\"].tolist()\n",
    "        if(type(years) == int):\n",
    "            country[\"all_refugees\"] = []\n",
    "            continue\n",
    "        all_refugees = total.loc[country_name][\"refugees\"].tolist()\n",
    "        country[\"all_refugees\"] = [{\"year\":years[i], \"refugees\":all_refugees[i]} for i in range(0, len(years))]\n",
    "    else:\n",
    "        country[\"all_refugees\"] = []\n",
    "\n",
    "with open(\"refugee_world.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5 Sources of Refugees (inbound) and Destinations for Refugees (outbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'unhcr_refugee.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7fabd370ffee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrefugee_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unhcr_refugee.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrefugee_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefugee_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0masylum_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefugee_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"asylum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3ve/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'unhcr_refugee.csv' does not exist"
     ]
    }
   ],
   "source": [
    "with open(\"world.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "refugee_table = pd.read_csv(\"unhcr_refugee.csv\", delimiter=',', encoding=\"latin-1\")\n",
    "refugee_table = clean_names(refugee_table)\n",
    "asylum_set = set(refugee_table[\"asylum\"].unique())\n",
    "# total = refugee_table.groupby([\"asylum\", \"year\"]).sum().reset_index().set_index(\"asylum\")\n",
    "# total = clean_names(total)\n",
    "\n",
    "tmp = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"origin\",\"refugees\"], ascending =False)\n",
    "tmp = tmp[tmp[\"asylum\"]!=tmp[\"origin\"]]\n",
    "# Top 5 places refugees are leaving to:\n",
    "asylum = tmp.groupby(\"origin\").head(5).set_index(\"origin\")\n",
    "\n",
    "refugees = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"asylum\",\"refugees\"], ascending =False)\n",
    "refugees = refugees[refugees[\"asylum\"]!=refugees[\"origin\"]]\n",
    "# Top 5 places refugees are coming from:\n",
    "refugees = refugees.groupby(\"asylum\").head(5).set_index(\"asylum\")\n",
    "\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in asylum_set) or (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        p = refugees.loc[country_name]\n",
    "        \n",
    "        if(isinstance(p[\"origin\"], str)):\n",
    "            country[\"inbound_countries\"] = [p[\"origin\"]]\n",
    "            country[\"inbound_num\"] = [int(p[\"refugees\"])]\n",
    "        else:\n",
    "            country[\"inbound_countries\"] = p[\"origin\"].tolist()\n",
    "            country[\"inbound_num\"] = p[\"refugees\"].tolist()\n",
    "        \n",
    "        try:\n",
    "            p = asylum.loc[country_name]\n",
    "        except:\n",
    "            continue\n",
    "        if(isinstance(p[\"asylum\"], str)):\n",
    "            country[\"outbound_countries\"] = [p[\"asylum\"]]\n",
    "            country[\"outbound_num\"] = [int(p[\"refugees\"])]\n",
    "        \n",
    "        else:\n",
    "            country[\"outbound_countries\"] = p[\"asylum\"].tolist()\n",
    "            country[\"outbound_num\"] = p[\"refugees\"].tolist()\n",
    "        \n",
    "#         for col in col_names:\n",
    "#             country[inbound] = p[col].tolist()\n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        country[\"inbound_countries\"] = []\n",
    "        country[\"inbound_num\"] = []\n",
    "        country[\"outbound_countries\"] = []\n",
    "        country[\"outbound_num\"] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refugee_world.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refugee Demographic Statistics:\n",
    "- Binding to JSON data\n",
    "\n",
    "- Using `unhcr_demographics.csv`\n",
    "\n",
    "- Breaks down \"Persons of Concern\" (see previous section for UNHCR definition) by gender and age\n",
    "\n",
    "- Source: http://popstats.unhcr.org/en/demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"world.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "demo = pd.read_csv(\"unhcr_demographics.csv\", converters = {}).fillna(0).replace(\"*\", int(0))\n",
    "for i in range(3, demo.shape[1]):\n",
    "    demo.iloc[:,i] = demo.iloc[:,i].astype(\"int32\")\n",
    "\n",
    "demo = demo.groupby([\"Year\", \"Country / territory of asylum/residence\"]).sum().reset_index()\n",
    "tmp = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = clean_names(demo)\n",
    "demo = demo.sort_values(by=[\"Country / territory of asylum/residence\", \"Year\"])\n",
    "demo_set = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = demo.set_index(\"Country / territory of asylum/residence\")\n",
    "col_names = demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Female0-4</th>\n",
       "      <th>Female5-11</th>\n",
       "      <th>Female5-17</th>\n",
       "      <th>Female12-17</th>\n",
       "      <th>Female18-59</th>\n",
       "      <th>Female60+</th>\n",
       "      <th>F:Unknown</th>\n",
       "      <th>F:Total</th>\n",
       "      <th>Male0-4</th>\n",
       "      <th>Male 5-11</th>\n",
       "      <th>Male5-17</th>\n",
       "      <th>Male12-17</th>\n",
       "      <th>Male18-59</th>\n",
       "      <th>Male60+</th>\n",
       "      <th>M:Unknown</th>\n",
       "      <th>M:Total</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country / territory of asylum/residence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Year  Female0-4  Female5-11  \\\n",
       "Country / territory of asylum/residence                                \n",
       "United States                            2015          0           0   \n",
       "United States                            2016          0           0   \n",
       "United States                            2017          0           0   \n",
       "\n",
       "                                         Female5-17  Female12-17  Female18-59  \\\n",
       "Country / territory of asylum/residence                                         \n",
       "United States                                     0            0            0   \n",
       "United States                                     0            0            0   \n",
       "United States                                     0            0            0   \n",
       "\n",
       "                                         Female60+  F:Unknown  F:Total  \\\n",
       "Country / territory of asylum/residence                                  \n",
       "United States                                    0          0        0   \n",
       "United States                                    0          0        0   \n",
       "United States                                    0          0        0   \n",
       "\n",
       "                                         Male0-4  Male 5-11  Male5-17  \\\n",
       "Country / territory of asylum/residence                                 \n",
       "United States                                  0          0         0   \n",
       "United States                                  0          0         0   \n",
       "United States                                  0          0         0   \n",
       "\n",
       "                                         Male12-17  Male18-59  Male60+  \\\n",
       "Country / territory of asylum/residence                                  \n",
       "United States                                    0          0        0   \n",
       "United States                                    0          0        0   \n",
       "United States                                    0          0        0   \n",
       "\n",
       "                                         M:Unknown  M:Total  total  \n",
       "Country / territory of asylum/residence                             \n",
       "United States                                    0        0      0  \n",
       "United States                                    0        0      0  \n",
       "United States                                    0        0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.loc[\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"world.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "min_year = {}\n",
    "\n",
    "demo = pd.read_csv(\"unhcr_demographics.csv\", converters = {}).fillna(0).replace(\"*\", int(0))\n",
    "for i in range(3, demo.shape[1]):\n",
    "    demo.iloc[:,i] = demo.iloc[:,i].astype(\"int32\")\n",
    "\n",
    "demo = demo.groupby([\"Year\", \"Country / territory of asylum/residence\"]).sum().reset_index()\n",
    "tmp = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = clean_names(demo)\n",
    "demo = demo.sort_values(by=[\"Country / territory of asylum/residence\", \"Year\"])\n",
    "demo_set = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = demo.set_index(\"Country / territory of asylum/residence\")\n",
    "col_names = demo.columns\n",
    "\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in demo_set) or (country[\"properties\"][\"name_long\"] in demo_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in demo_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        p = demo.loc[country_name]\n",
    "        min_year[country_name] = min(p[\"Year\"])\n",
    "        for col in col_names:\n",
    "            country[col] = p[col].tolist()\n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        for col in col_names:\n",
    "            country[col] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"refugee_world.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Demographic and Top 5 Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Add Demographic Data:\n",
    "Add demographic data to `.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"world.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "min_year = {}\n",
    "max_year = {}\n",
    "\n",
    "demo = pd.read_csv(\"unhcr_demographics.csv\", converters = {}).fillna(0).replace(\"*\", int(0))\n",
    "for i in range(3, demo.shape[1]):\n",
    "    demo.iloc[:,i] = demo.iloc[:,i].astype(\"int32\")\n",
    "\n",
    "demo = demo.groupby([\"Year\", \"Country / territory of asylum/residence\"]).sum().reset_index()\n",
    "tmp = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = clean_names(demo)\n",
    "demo = demo.sort_values(by=[\"Country / territory of asylum/residence\", \"Year\"])\n",
    "demo_set = set(demo[\"Country / territory of asylum/residence\"])\n",
    "demo = demo.set_index(\"Country / territory of asylum/residence\")\n",
    "col_names = demo.columns\n",
    "\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in demo_set) or (country[\"properties\"][\"name_long\"] in demo_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in demo_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        p = demo.loc[country_name]\n",
    "        min_year[country_name] = min(p[\"Year\"])\n",
    "        max_year[country_name] = max(p[\"Year\"])\n",
    "        for col in col_names:\n",
    "            country[col] = p[col].tolist()\n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        for col in col_names:\n",
    "            country[col] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Add Top 5 Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee_table = pd.read_csv(\"unhcr_refugees.csv\", delimiter=',', encoding=\"latin-1\").fillna(0).replace(\"*\", int(0))\n",
    "refugee_table = clean_names(refugee_table)\n",
    "for i in range(3, refugee_table.shape[1]):\n",
    "    refugee_table.iloc[:,i] = refugee_table.iloc[:,i].astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outbound Refugees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding countries that are not in min_year\n",
    "# This is effectively removing countries that are not in the demographics table:\n",
    "old_years = set()\n",
    "x = refugee_table[[country in min_year for country in refugee_table[\"origin\"]]]\n",
    "keep_array = []\n",
    "for row in x.iterrows():\n",
    "    origin = row[1][2]\n",
    "    year = row[1][0]\n",
    "    if year < min_year[origin] or year > max_year[origin]:\n",
    "        keep_array.append(False)\n",
    "        old_years.add(year)\n",
    "    else:\n",
    "        keep_array.append(True)\n",
    "        \n",
    "# keep arrays is all the rows where the years are with the max/min range of years from the \n",
    "# UNHCR demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_refugees = x.iloc[keep_array]\n",
    "tmp = all_refugees.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"origin\",\"refugees\"], ascending =False)\n",
    "\n",
    "# Old code without excluding years not in demographic data:\n",
    "# tmp = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"origin\",\"refugees\"], ascending =False)\n",
    "\n",
    "tmp = tmp[tmp[\"asylum\"]!=tmp[\"origin\"]]\n",
    "refugees = tmp.groupby(\"origin\").head(5).set_index(\"origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbound Refugees Seeking Asylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding countries that are not in min_year\n",
    "# This is effectively removing countries that are not in the demographics table:\n",
    "old_years2 = set()\n",
    "y = refugee_table[[country in min_year for country in refugee_table[\"asylum\"]]]\n",
    "keep_array2 = []\n",
    "for row in y.iterrows():\n",
    "    asylum = row[1][1]\n",
    "    year = row[1][0]\n",
    "    if year < min_year[asylum] or year > max_year[asylum]:\n",
    "        keep_array2.append(False)\n",
    "        old_years2.add(year)\n",
    "    else:\n",
    "        keep_array2.append(True)\n",
    "        \n",
    "# keep arrays is all the rows where the years are with the max/min range of years from the \n",
    "# UNHCR demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asylum = y.iloc[keep_array2]\n",
    "asylum = all_asylum.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"asylum\",\"refugees\"], ascending =False)\n",
    "\n",
    "# Old code without excluding years not in demographic data:\n",
    "# asylum = refugee_table.drop(\"year\", axis = 1).groupby([\"asylum\", \"origin\"]).sum().reset_index().sort_values([\"asylum\",\"refugees\"], ascending =False)\n",
    "\n",
    "asylum = asylum[asylum[\"asylum\"]!=asylum[\"origin\"]]\n",
    "\n",
    "# Top 5 places refugees are coming from:\n",
    "asylum = asylum.groupby(\"asylum\").head(5).set_index(\"asylum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create set of countries in asylum and origin columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum_set = set(x[\"origin\"].unique())\n",
    "\n",
    "for item in y[\"asylum\"]:\n",
    "    if item not in asylum_set:\n",
    "        asylum_set.add(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add top 5 data to `.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = []\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in asylum_set) or (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        \n",
    "        country_list.append(country_name)\n",
    "\n",
    "        try:\n",
    "            p = refugees.loc[country_name]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if(isinstance(p[\"asylum\"], str)):\n",
    "            if int(p[\"refugees\"]) < 1:\n",
    "                country[\"outbound_num\"] = []\n",
    "                country[\"outbound_countries\"] = []\n",
    "            else:\n",
    "                country[\"outbound_num\"] = [int(p[\"refugees\"])]\n",
    "                country[\"outbound_countries\"] = [p[\"asylum\"]]\n",
    "        \n",
    "        else:\n",
    "            num = p[\"refugees\"].tolist()\n",
    "            countries = p[\"asylum\"].tolist()\n",
    "            non_zero_idx = [x[0] for x in np.argwhere(np.array(num)>0)]\n",
    "            num_new = [num[i] for i in non_zero_idx]\n",
    "            countries_new = [countries[i] for i in non_zero_idx]\n",
    "            \n",
    "            country[\"outbound_num\"] = num_new\n",
    "            country[\"outbound_countries\"] = countries_new\n",
    "        \n",
    "        try:\n",
    "            p = asylum.loc[country_name]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if(isinstance(p[\"origin\"], str)):\n",
    "            if int(p[\"refugees\"]) < 1:\n",
    "                country[\"inbound_num\"] = []\n",
    "                country[\"inbound_countries\"] = []\n",
    "            else:\n",
    "                country[\"inbound_num\"] = [int(p[\"refugees\"])]\n",
    "                country[\"inbound_countries\"] = [p[\"origin\"]]\n",
    "\n",
    "        else:\n",
    "            num = p[\"refugees\"].tolist()\n",
    "            countries = p[\"origin\"].tolist()\n",
    "            non_zero_idx = [x[0] for x in np.argwhere(np.array(num)>0)]\n",
    "            num_new = [num[i] for i in non_zero_idx]\n",
    "            countries_new = [countries[i] for i in non_zero_idx]\n",
    "            \n",
    "            country[\"inbound_num\"] = num_new\n",
    "            country[\"inbound_countries\"] = countries_new\n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        country[\"inbound_countries\"] = []\n",
    "        country[\"inbound_num\"] = []\n",
    "        country[\"outbound_countries\"] = []\n",
    "        country[\"outbound_num\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Test to see if data encoded in JSON makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n",
      "outbound_countries: ['Canada', 'Spain', 'United States', 'Germany', 'Brazil']\n",
      "outbound_num: [4050, 3472, 1721, 550, 189]\n",
      "inbound_countries: ['Lao PDR', 'Peru', 'Various/Unknown', 'Colombia', 'Cuba']\n",
      "inbound_num: [9299, 8587, 5522, 5011, 4723]\n"
     ]
    }
   ],
   "source": [
    "#test(country_num):\n",
    "# Args:\n",
    "#     country_num = number of a country in the json file\n",
    "# Output:\n",
    "#     prints refugee data from a country to see if our code above worked correctly . \n",
    "def test(country_num):\n",
    "    country = data[\"features\"][country_num]\n",
    "    print(country[\"properties\"][\"name\"])\n",
    "    print(\"outbound_countries: \" + str(country[\"outbound_countries\"]))\n",
    "    print(\"outbound_num: \" + str(country[\"outbound_num\"]))\n",
    "    print(\"inbound_countries: \" + str(country[\"inbound_countries\"]))\n",
    "    print(\"inbound_num: \" + str(country[\"inbound_num\"]))\n",
    "\n",
    "test(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in Refugee Data by Year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where there are 0 refugees:\n",
    "asylum = asylum[asylum[\"refugees\"] > 0]\n",
    "refugees = refugees[refugees[\"refugees\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = all_refugees.set_index([\"origin\", \"asylum\"]).sort_values([\"origin\", \"asylum\", \"year\"])\n",
    "a = all_asylum.set_index([\"asylum\", \"origin\"]).sort_values([\"asylum\", \"origin\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbound_sum = all_refugees[[\"origin\", \"refugees\"]].groupby(\"origin\").sum()\n",
    "inbound_sum = all_asylum[[\"asylum\", \"refugees\"]].groupby(\"asylum\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = []\n",
    "missing = set()\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in asylum_set) or (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in asylum_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        \n",
    "        country_list.append(country_name)\n",
    "        # Outbound Refugees: (seeking refuge)\n",
    "        try:\n",
    "            p = r.loc[country_name]\n",
    "            top = refugees.loc[country_name]\n",
    "            top_names = top[\"asylum\"]\n",
    "        except:\n",
    "            country[\"outbound_year\"] = []\n",
    "            country[\"annual_outbound\"] = []\n",
    "            country[\"max_outbound\"] = 0\n",
    "            continue\n",
    "        \n",
    "        if(isinstance(top[\"asylum\"], str)):\n",
    "            if int(top[\"refugees\"]) < 1:\n",
    "                country[\"outbound_year\"] = []\n",
    "                country[\"annual_outbound\"] = []\n",
    "                country[\"max_outbound\"] = 0\n",
    "            else:\n",
    "                country[\"outbound_year\"] = [p.loc[top[0]][\"year\"].tolist()]\n",
    "                country[\"annual_outbound\"] = [p.loc[top[0]][\"refugees\"].tolist()]\n",
    "                country[\"max_outbound\"] = max(country[\"annual_outbound\"])\n",
    "        else:\n",
    "            country[\"outbound_year\"] = [[p.loc[country][\"year\"].tolist()] if isinstance(p.loc[country][\"year\"].tolist(), int) else p.loc[country][\"year\"].tolist() for country in top_names]\n",
    "            country[\"annual_outbound\"] = [[p.loc[country][\"refugees\"].tolist()] if isinstance(p.loc[country][\"refugees\"].tolist(), int) else p.loc[country][\"refugees\"].tolist()for country in top_names]\n",
    "            country[\"max_outbound\"] = max([max(x) for x in country[\"annual_outbound\"]])\n",
    "        \n",
    "        country[\"outbound_sum\"] = int(outbound_sum.loc[country_name][0])\n",
    "        \n",
    "        # Inbound Refugees: (asylum)\n",
    "        try:\n",
    "            p = a.loc[country_name]\n",
    "            top = asylum.loc[country_name]\n",
    "            top_names = top[\"origin\"]\n",
    "        except:\n",
    "            country[\"inbound_year\"] = []\n",
    "            country[\"annual_inbound\"] = []\n",
    "            country[\"max_inbound\"]= 0\n",
    "            country[\"inbound_sum\"] = 0\n",
    "            continue\n",
    "        \n",
    "        if(isinstance(top[\"origin\"], str)):\n",
    "            if int(top[\"refugees\"]) < 1:\n",
    "                country[\"inbound_year\"] = []\n",
    "                country[\"annual_inbound\"] = []\n",
    "                country[\"max_inbound\"]= 0\n",
    "            else:\n",
    "                country[\"inbound_year\"] = [p.loc[top[0]][\"year\"].tolist()]\n",
    "                country[\"annual_inbound\"] = [p.loc[top[0]][\"refugees\"].tolist()]\n",
    "                country[\"max_inbound\"] = max(country[\"annual_inbound\"])\n",
    "\n",
    "        else:\n",
    "            country[\"inbound_year\"] = [[p.loc[country][\"year\"].tolist()] if isinstance(p.loc[country][\"year\"].tolist(), int) else p.loc[country][\"year\"].tolist() for country in top_names]\n",
    "            country[\"annual_inbound\"] = [[p.loc[country][\"refugees\"].tolist()] if isinstance(p.loc[country][\"refugees\"].tolist(), int) else p.loc[country][\"refugees\"].tolist()for country in top_names]\n",
    "            country[\"max_inbound\"] = max([max(x) for x in country[\"annual_inbound\"]])\n",
    "            \n",
    "        country[\"inbound_sum\"] = int(inbound_sum.loc[country_name][0])\n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        country[\"outbound_year\"] = []\n",
    "        country[\"annual_outbound\"] = []\n",
    "        country[\"inbound_year\"] = []\n",
    "        country[\"annual_inbound\"] = []\n",
    "        country[\"inbound_sum\"] = 0\n",
    "        country[\"outbound_sum\"] = 0\n",
    "        country[\"max_outbound\"] = 0\n",
    "        country[\"max_inbound\"]= 0\n",
    "        missing.add(country[\"properties\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grenada\n",
      "outbound_year: [[2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017], [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017], [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017], [2010, 2015, 2016, 2017], [2014, 2016, 2017]]\n",
      "annual_outbound: [[325, 303, 292, 304, 294, 239, 67, 64], [15, 17, 19, 20, 23, 23, 24, 24], [0, 3, 5, 6, 7, 8, 9, 15], [5, 0, 0, 0], [0, 1, 0]]\n",
      "inbound_year: [[2010, 2011], [2015, 2016, 2017]]\n",
      "annual_inbound: [[0, 3], [1, 1, 0]]\n",
      "outbound_countries: ['Canada', 'United States', 'United Kingdom', 'Germany', 'Italy']\n",
      "inbound_countries: ['Iran', 'Syria']\n",
      "outbound_sum: 2112\n",
      "inbound_sum: 5\n",
      "years:[2010, 2011, 2015, 2016, 2017]\n",
      "max_outbound: 325\n",
      "max_inbound: 3\n"
     ]
    }
   ],
   "source": [
    "def test2(country_num):\n",
    "    country = data[\"features\"][country_num]\n",
    "    print(country[\"properties\"][\"name\"])\n",
    "    print(\"outbound_year: \" + str(country[\"outbound_year\"]))\n",
    "    print(\"annual_outbound: \" + str(country[\"annual_outbound\"]))\n",
    "    print(\"inbound_year: \" + str(country[\"inbound_year\"]))\n",
    "    print(\"annual_inbound: \" + str(country[\"annual_inbound\"]))\n",
    "    print(\"outbound_countries: \" + str(country[\"outbound_countries\"]))\n",
    "    print(\"inbound_countries: \" + str(country[\"inbound_countries\"]))\n",
    "    print(\"outbound_sum: \" + str(country[\"outbound_sum\"]))\n",
    "    print(\"inbound_sum: \" + str(country[\"inbound_sum\"]))\n",
    "    print(\"years:\" + str(country[\"Year\"]))\n",
    "    print(\"max_outbound: \" + str(country[\"max_outbound\"]))\n",
    "    print(\"max_inbound: \" + str(country[\"max_inbound\"]))\n",
    "\n",
    "test2(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Persons of Concern Data:\n",
    "\n",
    "According to UNHCR, the demographics data does not align with the total persons of concern data:\n",
    "> This page presents information about persons of concern broken down by sex and age, as well as by location within the country of residence (where such information is available). Note that data broken down in this way is not always available, so it may not be possible to reconcile the figures on this page with those on the Persons of Concern and Time Series pages. Such data is available since 2000.\n",
    "\n",
    "*Source: http://popstats.unhcr.org/en/demographics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = pd.read_csv(\"persons_of_concern.csv\", delimiter=',', encoding=\"latin-1\", converters = {}).fillna(0).replace(\"*\", int(0))\n",
    "persons[\"Total Population\"] = persons[\"Total Population\"].astype(\"int32\")\n",
    "persons_sum = clean_names(persons.groupby([\"Country / territory of asylum/residence\", \"Year\"]).sum().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_array = []\n",
    "missing_country = set()\n",
    "\n",
    "for row in persons_sum.iterrows():\n",
    "    country = row[1][0]\n",
    "    year = row[1][1]\n",
    "\n",
    "    if country not in min_year or country not in max_year:\n",
    "        keep_array.append(False)\n",
    "        missing_country.add(country)\n",
    "        \n",
    "    elif year < min_year[country] or year > max_year[country]:\n",
    "        keep_array.append(False)\n",
    "        old_years.add(year)\n",
    "    else:\n",
    "        keep_array.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_clean = persons_sum.iloc[keep_array]\n",
    "persons_clean.head(5)\n",
    "persons_set = set(persons_clean[\"Country / territory of asylum/residence\"])\n",
    "persons_clean = persons_clean.set_index(\"Country / territory of asylum/residence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = set()\n",
    "\n",
    "for country in data[\"features\"]:\n",
    "    if (country[\"properties\"][\"name\"] in persons_set) or (country[\"properties\"][\"name_long\"] in persons_set):\n",
    "        if (country[\"properties\"][\"name_long\"] in persons_set):\n",
    "            country_name = country[\"properties\"][\"name_long\"]\n",
    "        else:\n",
    "            country_name = country[\"properties\"][\"name\"]\n",
    "        \n",
    "        p = persons_clean.loc[country_name]\n",
    "        country[\"total_no_demo\"] = p[\"Total Population\"].tolist()\n",
    "        \n",
    "    \n",
    "    # Country not in UNHCR List:\n",
    "    else:\n",
    "        missing_countries.add(country[\"properties\"][\"name\"])\n",
    "        country[\"total_no_demo\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refugee_world.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
